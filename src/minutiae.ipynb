{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting 0:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nis\\Downloads\\DarKSkuLL\\FingerNet\\src\\minutiae.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=832'>833</a>\u001b[0m \u001b[39m#%%\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=833'>834</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=834'>835</a>\u001b[0m     \u001b[39m# args\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=835'>836</a>\u001b[0m     main()\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=836'>837</a>\u001b[0m     \u001b[39m# train()\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=837'>838</a>\u001b[0m     \u001b[39m# for folder in test_set:\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=838'>839</a>\u001b[0m     \u001b[39m#     test([folder,], pretrain, output_dir+\"/\", test_num=258, draw=False) \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=844'>845</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=845'>846</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\nis\\Downloads\\DarKSkuLL\\FingerNet\\src\\minutiae.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=827'>828</a>\u001b[0m \u001b[39melif\u001b[39;00m args\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdeploy\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=828'>829</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, folder \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(deploy_set):\n\u001b[1;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=829'>830</a>\u001b[0m         deploy(folder, \u001b[39mstr\u001b[39;49m(i))\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=830'>831</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=831'>832</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\nis\\Downloads\\DarKSkuLL\\FingerNet\\src\\minutiae.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=749'>750</a>\u001b[0m     deploy_set \u001b[39m=\u001b[39m deploy_set\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimages/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=750'>751</a>\u001b[0m     _, img_name \u001b[39m=\u001b[39m get_files_in_folder(deploy_set, \u001b[39m'\u001b[39m\u001b[39m.tiff\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=751'>752</a>\u001b[0m img_size \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(deploy_set\u001b[39m+\u001b[39mimg_name[\u001b[39m0\u001b[39;49m]\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.tiff\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mshape\n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=752'>753</a>\u001b[0m img_size \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img_size, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\u001b[39m/\u001b[39m\u001b[39m8\u001b[39m\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m      \n\u001b[0;32m    <a href='vscode-notebook-cell://ssh-remote%2Bbio/c%3A/Users/nis/Downloads/DarKSkuLL/FingerNet/src/minutiae.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=753'>754</a>\u001b[0m main_net_model \u001b[39m=\u001b[39m get_main_net((img_size[\u001b[39m0\u001b[39m],img_size[\u001b[39m1\u001b[39m],\u001b[39m1\u001b[39m), pretrain)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "#%% Imports\n",
    "import os, sys, cv2, pickle\n",
    "from multiprocessing import Pool\n",
    "from functools import partial,reduce\n",
    "from time import time\n",
    "import matplotlib\n",
    "# Force matplotlib to not use any Xwindows backend.\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from utils import *\n",
    "from scipy import misc, ndimage, signal, sparse, io\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Flatten,Activation,Lambda,Dense\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D,UpSampling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import PReLU\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "import tensorflow as tf\n",
    "#%% Arguments to the program\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Train-Test-Deploy')\n",
    "parser.add_argument('GPU', type=str, default=\"1\",\n",
    "                    help='Your GPU ID')\n",
    "parser.add_argument('mode', type=str, default=\"deploy\",\n",
    "                    help='train-test, test or deploy')\n",
    "args = parser.parse_args(\"1 deploy\".split())\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.GPU\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth=True\n",
    "# sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# config = K.tf.compat.v1.ConfigProto(gpu_options=K.tf.GPUOptions(allow_growth=True))\n",
    "# sess = K.tf.compat.v1.Session(config=config)\n",
    "# K.set_session(sess)\n",
    "\n",
    "batch_size = 2\n",
    "use_multiprocessing = True\n",
    "#%% data training\n",
    "train_set = ['../datasets/CISL24218/',]\n",
    "train_sample_rate = None\n",
    "test_set = ['../datasets/NISTSD27/',]\n",
    "# deploy_set = ['../datasets/NISTSD27/images/','../datasets/CISL24218/', \\\n",
    "#             '../datasets/FVC2002DB2A/','../datasets/NIST4/','../datasets/NIST14/']\n",
    "# deploy_set = ['../datasets/Anguli_2.5k_50k/']\n",
    "deploy_set = ['D:/anguli_fingerprint_datasets/anguli_imagenet/']\n",
    "\n",
    "# deploy_set = ['../datasets/fvc2006_dbs_combined/',]\n",
    "pretrain = '../models/released_version/Model.model'\n",
    "output_dir = '../output/'+datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "logging = init_log(output_dir)\n",
    "# copy_file(sys.path[0]+'/'+sys.argv[0], output_dir+'/')\n",
    "#%% function\n",
    "# image normalization\n",
    "def img_normalization(img_input, m0=0.0, var0=1.0):\n",
    "    m = K.mean(img_input, axis=[1,2,3], keepdims=True)\n",
    "    var = K.var(img_input, axis=[1,2,3], keepdims=True)\n",
    "    after = K.sqrt(var0*K.tf.square(img_input-m)/var)\n",
    "    image_n = K.tf.where(K.tf.greater(img_input, m), m0+after, m0-after)\n",
    "    return image_n\n",
    "#%% training\n",
    "# atan2 function\n",
    "def atan2(y_x):\n",
    "    y, x = y_x[0], y_x[1]+K.epsilon()\n",
    "    atan = K.tf.atan(y/x)\n",
    "    angle = K.tf.where(K.tf.greater(x,0.0), atan, K.tf.zeros_like(x))\n",
    "    angle = K.tf.where(K.tf.logical_and(K.tf.less(x,0.0),  K.tf.greater_equal(y,0.0)), atan+np.pi, angle)\n",
    "    angle = K.tf.where(K.tf.logical_and(K.tf.less(x,0.0),  K.tf.less(y,0.0)), atan-np.pi, angle)\n",
    "    return angle\n",
    "\n",
    "# traditional orientation estimation\n",
    "def orientation(image, stride=8, window=17):\n",
    "    with K.tf.name_scope('orientation'):\n",
    "        assert image.get_shape().as_list()[3] == 1, 'Images must be grayscale'\n",
    "        strides = [1, stride, stride, 1]\n",
    "        E = np.ones([window, window, 1, 1])\n",
    "        sobelx = np.reshape(np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=float), [3, 3, 1, 1])\n",
    "        sobely = np.reshape(np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=float), [3, 3, 1, 1])\n",
    "        gaussian = np.reshape(gaussian2d((5, 5), 1), [5, 5, 1, 1])\n",
    "        with K.tf.name_scope('sobel_gradient'):\n",
    "            Ix = K.tf.nn.conv2d(image, sobelx, strides=[1,1,1,1], padding='SAME', name='sobel_x')\n",
    "            Iy = K.tf.nn.conv2d(image, sobely, strides=[1,1,1,1], padding='SAME', name='sobel_y')\n",
    "        with K.tf.name_scope('eltwise_1'):\n",
    "            Ix2 = K.tf.multiply(Ix, Ix, name='IxIx')\n",
    "            Iy2 = K.tf.multiply(Iy, Iy, name='IyIy')\n",
    "            Ixy = K.tf.multiply(Ix, Iy, name='IxIy')\n",
    "        with K.tf.name_scope('range_sum'):\n",
    "            Gxx = K.tf.nn.conv2d(Ix2, E, strides=strides, padding='SAME', name='Gxx_sum')\n",
    "            Gyy = K.tf.nn.conv2d(Iy2, E, strides=strides, padding='SAME', name='Gyy_sum')\n",
    "            Gxy = K.tf.nn.conv2d(Ixy, E, strides=strides, padding='SAME', name='Gxy_sum')\n",
    "        with K.tf.name_scope('eltwise_2'):\n",
    "            Gxx_Gyy = K.tf.subtract(Gxx, Gyy, name='Gxx_Gyy')\n",
    "            theta = atan2([2*Gxy, Gxx_Gyy]) + np.pi\n",
    "        # two-dimensional low-pass filter: Gaussian filter here\n",
    "        with K.tf.name_scope('gaussian_filter'):\n",
    "            phi_x = K.tf.nn.conv2d(K.tf.cos(theta), gaussian, strides=[1,1,1,1], padding='SAME', name='gaussian_x')\n",
    "            phi_y = K.tf.nn.conv2d(K.tf.sin(theta), gaussian, strides=[1,1,1,1], padding='SAME', name='gaussian_y')\n",
    "            theta = atan2([phi_y, phi_x])/2\n",
    "    return theta\n",
    "\n",
    "def get_tra_ori():\n",
    "    img_input=Input(shape=(None, None, 1))\n",
    "    theta = Lambda(orientation)(img_input)\n",
    "    model = Model(inputs=[img_input,], outputs=[theta,])\n",
    "    return model\n",
    "tra_ori_model = get_tra_ori()\n",
    "\n",
    "# def get_maximum_img_size_and_names(dataset, sample_rate=None):\n",
    "#     if sample_rate is None:\n",
    "#         sample_rate = [1]*len(dataset)\n",
    "#     img_name, folder_name, img_size = [], [], []\n",
    "#     for folder, rate in zip(dataset, sample_rate):\n",
    "#         _, img_name_t = get_files_in_folder(folder+'images/', '.tif')\n",
    "#         img_name.extend(img_name_t.tolist()*rate)\n",
    "#         folder_name.extend([folder]*img_name_t.shape[0]*rate)\n",
    "#         img_size.append(np.array(cv2.imread(folder+'images/'+img_name_t[0]+'.tif').shape))\n",
    "#     img_name = np.asarray(img_name)\n",
    "#     folder_name = np.asarray(folder_name)\n",
    "#     img_size = np.max(np.asarray(img_size), axis=0)\n",
    "#     # print('img_size: ', img_size)\n",
    "#     # let img_size % 8 == 0\n",
    "#     # img_size = np.array(np.ceil(img_size/8)*8,dtype=np.int32)\n",
    "    \n",
    "#     return img_name, folder_name, img_size\n",
    "import cv2\n",
    "\n",
    "def get_maximum_img_size_and_names(dataset, sample_rate=None, target_size=(512, 512)):\n",
    "    if sample_rate is None:\n",
    "        sample_rate = [1] * len(dataset)\n",
    "    img_name, folder_name, img_size = [], [], []\n",
    "    for folder, rate in zip(dataset, sample_rate):\n",
    "        _, img_name_t = get_files_in_folder(folder + 'images/', '.tiff')\n",
    "        img_name.extend(img_name_t.tolist() * rate)\n",
    "        folder_name.extend([folder] * img_name_t.shape[0] * rate)\n",
    "        img = cv2.imread(folder + 'images/' + img_name_t[0] + '.tiff', cv2.IMREAD_GRAYSCALE)\n",
    "        img_size.append(np.array(target_size))  # Use the target_size instead of the original image shape\n",
    "    img_name = np.asarray(img_name)\n",
    "    folder_name = np.asarray(folder_name)\n",
    "    img_size = np.max(np.asarray(img_size), axis=0)\n",
    "    print(img_size)\n",
    "    return img_name, folder_name, img_size\n",
    "\n",
    "def sub_load_data(data, img_size, aug): \n",
    "    img_name, dataset = data\n",
    "    img = cv2.imread(dataset+'images/'+img_name+'.tiff')\n",
    "    seg = cv2.imread(dataset+'seg_labels/'+img_name+'.png')   \n",
    "\n",
    "    try:\n",
    "        ali = cv2.imread(dataset+'ori_labels/'+img_name+'.tiff')\n",
    "    except:\n",
    "        ali = np.zeros_like(img)\n",
    "    \n",
    "    mnt = np.array(mnt_reader(dataset+'mnt_labels/'+img_name+'.mnt'), dtype=float)\n",
    "    if any(img.shape != img_size):\n",
    "        # print(img.shape, img_size)\n",
    "        # random pad mean values to reach required shape\n",
    "        tra = np.int32(np.random.rand(3) * (np.array(img_size) - np.array(img.shape))[:3])\n",
    "        img_t = np.ones(img_size)*np.mean(img)\n",
    "        seg_t = np.zeros(img_size)\n",
    "        ali_t = np.ones(img_size)*np.mean(ali)\n",
    "        img_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = img\n",
    "        seg_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = seg\n",
    "        ali_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = ali\n",
    "        img = img_t\n",
    "        seg = seg_t\n",
    "        ali = ali_t\n",
    "        mnt = mnt+np.array([tra[1],tra[0],0])\n",
    "    #     if np.random.rand()<aug:           \n",
    "    #         tra = np.int32(np.random.rand(3) * (np.array(img_size) - np.array(img.shape))[:3])\n",
    "    #     else:\n",
    "    #         tra = np.int32(0.5*(np.array(img_size)-np.array(img.shape)))\n",
    "    #     img_t = np.ones(img_size)*np.mean(img)\n",
    "    #     seg_t = np.zeros(img_size)\n",
    "    #     ali_t = np.ones(img_size)*np.mean(ali)\n",
    "    #     img_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = img\n",
    "    #     seg_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = seg\n",
    "    #     ali_t[tra[0]:tra[0]+img.shape[0],tra[1]:tra[1]+img.shape[1]] = ali\n",
    "    #     img = img_t\n",
    "    #     seg = seg_t\n",
    "    #     ali = ali_t\n",
    "    #     mnt = mnt+np.array([tra[1],tra[0],0]) \n",
    "    if np.random.rand()<aug:\n",
    "        # random rotation [0 - 360] & translation img_size / 4\n",
    "        rot = np.random.rand() * 360\n",
    "        tra = (np.random.rand(3) - 0.5) / 2 * img_size\n",
    "        img = ndimage.rotate(img, rot, reshape=False, mode='reflect')\n",
    "        img = ndimage.shift(img, tra, mode='reflect')\n",
    "        seg = ndimage.rotate(seg, rot, reshape=False, mode='constant')\n",
    "        seg = ndimage.shift(seg, tra, mode='constant')\n",
    "        ali = ndimage.rotate(ali, rot, reshape=False, mode='reflect')\n",
    "        ali = ndimage.shift(ali, tra, mode='reflect') \n",
    "        mnt_r = point_rot(mnt[:, :2], rot/180*np.pi, img.shape, img.shape)  \n",
    "        mnt = np.column_stack((mnt_r+tra[[1, 0]], mnt[:, 2]-rot/180*np.pi))\n",
    "    # only keep mnt that stay in pic & not on border\n",
    "    mnt = mnt[(8<=mnt[:,0])*(mnt[:,0]<img_size[1]-8)*(8<=mnt[:, 1])*(mnt[:,1]<img_size[0]-8), :]\n",
    "    return img, seg, ali, mnt   \n",
    "\n",
    "def load_data(dataset, tra_ori_model, rand=False, aug=0.0, batch_size=1, sample_rate=None):\n",
    "    if type(dataset[0]) == str:\n",
    "        img_name, folder_name, img_size = get_maximum_img_size_and_names(dataset, sample_rate)\n",
    "    else:\n",
    "        img_name, folder_name, img_size = dataset\n",
    "    if rand:\n",
    "        rand_idx = np.arange(len(img_name))\n",
    "        np.random.shuffle(rand_idx)\n",
    "        img_name = img_name[rand_idx]\n",
    "        folder_name = folder_name[rand_idx]\n",
    "    if batch_size > 1 and use_multiprocessing==True:\n",
    "        p = Pool(batch_size)        \n",
    "    p_sub_load_data = partial(sub_load_data, img_size=img_size, aug=aug)\n",
    "    for i in range(0,len(img_name), batch_size):\n",
    "        have_alignment = np.ones([batch_size, 1, 1, 1])\n",
    "        # print(batch_size, img_size[0], img_size[1] )\n",
    "        image = np.zeros((batch_size, img_size[0], img_size[1], 1))\n",
    "        segment = np.zeros((batch_size, img_size[0], img_size[1], 1))\n",
    "        alignment = np.zeros((batch_size, img_size[0], img_size[1], 1))\n",
    "        minutiae_w = np.zeros((batch_size, img_size[0]//8, img_size[1]//8, 1))-1\n",
    "        minutiae_h = np.zeros((batch_size, img_size[0]//8, img_size[1]//8, 1))-1\n",
    "        minutiae_o = np.zeros((batch_size, img_size[0]//8, img_size[1]//8, 1))-1\n",
    "        batch_name = [img_name[(i+j)%len(img_name)] for j in range(batch_size)]\n",
    "        batch_f_name = [folder_name[(i+j)%len(img_name)] for j in range(batch_size)]\n",
    "        if batch_size > 1 and use_multiprocessing==True:    \n",
    "            results = p.map(p_sub_load_data, zip(batch_name, batch_f_name))\n",
    "        else:\n",
    "            results = list(map(p_sub_load_data, zip(batch_name, batch_f_name)))\n",
    "        for j in range(batch_size):\n",
    "            \n",
    "            img, seg, ali, mnt = results[j]\n",
    "    \n",
    "            if np.sum(ali) == 0:\n",
    "                have_alignment[j, 0, 0, 0] = 0\n",
    "            image[j, :, :, 0] = img[:, :, 0] / 255.0\n",
    "            segment[j, :, :, 0] = seg[:, :, 0] / 255.0\n",
    "            alignment[j, :, :, 0] = ali[:, :, 0] / 255.0\n",
    "            minutiae_w[j, (mnt[:, 1]/8).astype(int), (mnt[:, 0]/8).astype(int), 0] = mnt[:, 0] % 8\n",
    "            minutiae_h[j, (mnt[:, 1]/8).astype(int), (mnt[:, 0]/8).astype(int), 0] = mnt[:, 1] % 8\n",
    "            minutiae_o[j, (mnt[:, 1]/8).astype(int), (mnt[:, 0]/8).astype(int), 0] = mnt[:, 2]\n",
    "        # get seg\n",
    "        label_seg = segment[:, ::8, ::8, :]\n",
    "        label_seg[label_seg>0] = 1\n",
    "        label_seg[label_seg<=0] = 0\n",
    "        minutiae_seg = (minutiae_o!=-1).astype(float)\n",
    "        # get ori & mnt\n",
    "        orientation = tra_ori_model.predict(alignment)        \n",
    "        orientation = orientation/np.pi*180+90\n",
    "        orientation[orientation>=180.0] = 0.0 # orientation [0, 180)\n",
    "        minutiae_o = minutiae_o/np.pi*180+90 # [90, 450)\n",
    "        minutiae_o[minutiae_o>360] = minutiae_o[minutiae_o>360]-360 # to current coordinate system [0, 360)\n",
    "        minutiae_ori_o = np.copy(minutiae_o) # copy one\n",
    "        minutiae_ori_o[minutiae_ori_o>=180] = minutiae_ori_o[minutiae_ori_o>=180]-180 # for strong ori label [0,180)      \n",
    "        # ori 2 gaussian\n",
    "        gaussian_pdf = signal.gaussian(361, 3)\n",
    "        y = np.reshape(np.arange(1, 180, 2), [1,1,1,-1])\n",
    "        delta = np.array(np.abs(orientation - y), dtype=int)\n",
    "        delta = np.minimum(delta, 180-delta)+180\n",
    "        label_ori = gaussian_pdf[delta]\n",
    "        # ori_o 2 gaussian\n",
    "        delta = np.array(np.abs(minutiae_ori_o - y), dtype=int)\n",
    "        delta = np.minimum(delta, 180-delta)+180\n",
    "        label_ori_o = gaussian_pdf[delta] \n",
    "        # mnt_o 2 gaussian\n",
    "        y = np.reshape(np.arange(1, 360, 2), [1,1,1,-1])\n",
    "        delta = np.array(np.abs(minutiae_o - y), dtype=int)  \n",
    "        delta = np.minimum(delta, 360-delta)+180\n",
    "        label_mnt_o = gaussian_pdf[delta]         \n",
    "        # w 2 gaussian\n",
    "        gaussian_pdf = signal.gaussian(17, 2)\n",
    "        y = np.reshape(np.arange(0, 8), [1,1,1,-1])\n",
    "        delta = (minutiae_w-y+8).astype(int)\n",
    "        label_mnt_w = gaussian_pdf[delta]\n",
    "        # h 2 gaussian\n",
    "        delta = (minutiae_h-y+8).astype(int)\n",
    "        label_mnt_h = gaussian_pdf[delta]\n",
    "        # mnt cls label -1:neg, 0:no care, 1:pos\n",
    "        label_mnt_s = np.copy(minutiae_seg)\n",
    "        label_mnt_s[label_mnt_s==0] = -1 # neg to -1\n",
    "        label_mnt_s = (label_mnt_s+ndimage.maximum_filter(label_mnt_s, size=(1,3,3,1)))/2 # around 3*3 pos -> 0\n",
    "        # apply segmentation\n",
    "        label_ori = label_ori * label_seg * have_alignment\n",
    "        label_ori_o = label_ori_o * minutiae_seg\n",
    "        label_mnt_o = label_mnt_o * minutiae_seg\n",
    "        label_mnt_w = label_mnt_w * minutiae_seg\n",
    "        label_mnt_h = label_mnt_h * minutiae_seg\n",
    "        yield image, label_ori, label_ori_o, label_seg, label_mnt_w, label_mnt_h, label_mnt_o, label_mnt_s, batch_name\n",
    "    if batch_size > 1 and use_multiprocessing==True:\n",
    "        p.close()\n",
    "        p.join()\n",
    "    return\n",
    "\n",
    "def merge_mul(x):\n",
    "    return reduce(lambda x,y:x*y, x)\n",
    "def merge_sum(x):\n",
    "    return reduce(lambda x,y:x+y, x)\n",
    "def reduce_sum(x):\n",
    "    return K.sum(x,axis=-1,keepdims=True) \n",
    "def merge_concat(x):\n",
    "    return K.tf.concat(x,3)\n",
    "def select_max(x):\n",
    "    x = x / (K.max(x, axis=-1, keepdims=True)+K.epsilon())\n",
    "    x = K.tf.where(K.tf.greater(x, 0.999), x, K.tf.zeros_like(x)) # select the biggest one\n",
    "    x = x / (K.sum(x, axis=-1, keepdims=True)+K.epsilon()) # prevent two or more ori is selected\n",
    "    return x  \n",
    "def conv_bn(bottom, w_size, name, strides=(1,1), dilation_rate=(1,1)):\n",
    "    top = Conv2D(w_size[0], (w_size[1],w_size[2]),\n",
    "        kernel_regularizer=l2(5e-5),\n",
    "        padding='same', \n",
    "        strides=strides,\n",
    "        dilation_rate=dilation_rate,\n",
    "        name='conv-'+name)(bottom)\n",
    "    top = BatchNormalization(name='bn-'+name)(top)\n",
    "    return top\n",
    "def conv_bn_prelu(bottom, w_size, name, strides=(1,1), dilation_rate=(1,1)):\n",
    "    if dilation_rate == (1,1):\n",
    "        conv_type = 'conv'\n",
    "    else:\n",
    "        conv_type = 'atrousconv'\n",
    "    top = Conv2D(w_size[0], (w_size[1],w_size[2]),\n",
    "        kernel_regularizer=l2(5e-5),\n",
    "        padding='same', \n",
    "        strides=strides,\n",
    "        dilation_rate=dilation_rate,\n",
    "        name=conv_type+name)(bottom)\n",
    "    top = BatchNormalization(name='bn-'+name)(top)\n",
    "    top=PReLU(alpha_initializer='zero', shared_axes=[1,2], name='prelu-'+name)(top)\n",
    "    return top\n",
    "def get_main_net(input_shape=(512,512,1), weights_path=None):\n",
    "    img_input = tf.keras.Input(shape=(512, 512, 1))\n",
    "    \n",
    "    bn_img=Lambda(lambda x: img_normalization(x, m0=0.0, var0=1.0), name='img_norm')(img_input)\n",
    "    # feature extraction VGG\n",
    "    conv=conv_bn_prelu(bn_img, (64,3,3), '1_1') \n",
    "    conv=conv_bn_prelu(conv, (64,3,3), '1_2')\n",
    "    conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv)\n",
    "\n",
    "    conv=conv_bn_prelu(conv, (128,3,3), '2_1') \n",
    "    conv=conv_bn_prelu(conv, (128,3,3), '2_2') \n",
    "    conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv)\n",
    "\n",
    "    conv=conv_bn_prelu(conv, (256,3,3), '3_1') \n",
    "    conv=conv_bn_prelu(conv, (256,3,3), '3_2') \n",
    "    conv=conv_bn_prelu(conv, (256,3,3), '3_3')   \n",
    "    conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(conv)\n",
    "\n",
    "    # multi-scale ASPP\n",
    "    scale_1=conv_bn_prelu(conv, (256,3,3), '4_1', dilation_rate=(1,1))\n",
    "    ori_1=conv_bn_prelu(scale_1, (128,1,1), 'ori_1_1')\n",
    "    ori_1=Conv2D(90, (1,1), padding='same', name='ori_1_2')(ori_1)\n",
    "    seg_1=conv_bn_prelu(scale_1, (128,1,1), 'seg_1_1')\n",
    "    seg_1=Conv2D(1, (1,1), padding='same', name='seg_1_2')(seg_1)\n",
    "\n",
    "    scale_2=conv_bn_prelu(conv, (256,3,3), '4_2', dilation_rate=(4,4))\n",
    "    ori_2=conv_bn_prelu(scale_2, (128,1,1), 'ori_2_1')\n",
    "    ori_2=Conv2D(90, (1,1), padding='same', name='ori_2_2')(ori_2)    \n",
    "    seg_2=conv_bn_prelu(scale_2, (128,1,1), 'seg_2_1')\n",
    "    seg_2=Conv2D(1, (1,1), padding='same', name='seg_2_2')(seg_2)\n",
    "\n",
    "    scale_3=conv_bn_prelu(conv, (256,3,3), '4_3', dilation_rate=(8,8))\n",
    "    ori_3=conv_bn_prelu(scale_3, (128,1,1), 'ori_3_1')\n",
    "    ori_3=Conv2D(90, (1,1), padding='same', name='ori_3_2')(ori_3)  \n",
    "    seg_3=conv_bn_prelu(scale_3, (128,1,1), 'seg_3_1')\n",
    "    seg_3=Conv2D(1, (1,1), padding='same', name='seg_3_2')(seg_3)\n",
    "\n",
    "    # sum fusion for ori\n",
    "    ori_out=Lambda(merge_sum)([ori_1, ori_2, ori_3]) \n",
    "    ori_out_1=Activation('sigmoid', name='ori_out_1')(ori_out)\n",
    "    ori_out_2=Activation('sigmoid', name='ori_out_2')(ori_out)\n",
    "\n",
    "    # sum fusion for segmentation\n",
    "    seg_out=Lambda(merge_sum)([seg_1, seg_2, seg_3])\n",
    "    seg_out=Activation('sigmoid', name='seg_out')(seg_out)\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # enhance part\n",
    "    filters_cos, filters_sin = gabor_bank(stride=2, Lambda=8)\n",
    "    filter_img_real = Conv2D(filters_cos.shape[3],(filters_cos.shape[0],filters_cos.shape[1]),\n",
    "        weights=[filters_cos, np.zeros([filters_cos.shape[3]])], padding='same',\n",
    "        name='enh_img_real_1')(img_input)\n",
    "    filter_img_imag = Conv2D(filters_sin.shape[3],(filters_sin.shape[0],filters_sin.shape[1]),\n",
    "        weights=[filters_sin, np.zeros([filters_sin.shape[3]])], padding='same',\n",
    "        name='enh_img_imag_1')(img_input)\n",
    "    ori_peak = Lambda(ori_highest_peak)(ori_out_1)\n",
    "    ori_peak = Lambda(select_max)(ori_peak) # select max ori and set it to 1\n",
    "    upsample_ori = UpSampling2D(size=(8,8))(ori_peak)\n",
    "    seg_round = Activation('softsign')(seg_out)      \n",
    "    upsample_seg = UpSampling2D(size=(8,8))(seg_round)\n",
    "    mul_mask_real = Lambda(merge_mul)([filter_img_real, upsample_ori])\n",
    "    enh_img_real = Lambda(reduce_sum, name='enh_img_real_2')(mul_mask_real)\n",
    "    mul_mask_imag = Lambda(merge_mul)([filter_img_imag, upsample_ori])\n",
    "    enh_img_imag = Lambda(reduce_sum, name='enh_img_imag_2')(mul_mask_imag)\n",
    "    enh_img = Lambda(atan2, name='phase_img')([enh_img_imag, enh_img_real])\n",
    "    enh_seg_img = Lambda(merge_concat, name='phase_seg_img')([enh_img, upsample_seg])\n",
    "    # ----------------------------------------------------------------------------\n",
    "    # mnt part\n",
    "    mnt_conv=conv_bn_prelu(enh_seg_img, (64,9,9), 'mnt_1_1') \n",
    "    mnt_conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(mnt_conv)\n",
    "\n",
    "    mnt_conv=conv_bn_prelu(mnt_conv, (128,5,5), 'mnt_2_1') \n",
    "    mnt_conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(mnt_conv)\n",
    "\n",
    "    mnt_conv=conv_bn_prelu(mnt_conv, (256,3,3), 'mnt_3_1')  \n",
    "    mnt_conv=MaxPooling2D(pool_size=(2,2),strides=(2,2))(mnt_conv)\n",
    "    print(\"start\")\n",
    "    print(mnt_conv.shape)    \n",
    "    print(\"end\")\n",
    "    mnt_o_1=Lambda(merge_concat)([mnt_conv, ori_out_1])\n",
    "    mnt_o_2=conv_bn_prelu(mnt_o_1, (256,1,1), 'mnt_o_1_1')\n",
    "    mnt_o_3=Conv2D(180, (1,1), padding='same', name='mnt_o_1_2')(mnt_o_2)\n",
    "    mnt_o_out=Activation('sigmoid', name='mnt_o_out')(mnt_o_3)\n",
    "\n",
    "    mnt_w_1=conv_bn_prelu(mnt_conv, (256,1,1), 'mnt_w_1_1')\n",
    "    mnt_w_2=Conv2D(8, (1,1), padding='same', name='mnt_w_1_2')(mnt_w_1)\n",
    "    mnt_w_out=Activation('sigmoid', name='mnt_w_out')(mnt_w_2)\n",
    "\n",
    "    mnt_h_1=conv_bn_prelu(mnt_conv, (256,1,1), 'mnt_h_1_1')\n",
    "    mnt_h_2=Conv2D(8, (1,1), padding='same', name='mnt_h_1_2')(mnt_h_1)\n",
    "    mnt_h_out=Activation('sigmoid', name='mnt_h_out')(mnt_h_2) \n",
    "\n",
    "    mnt_s_1=conv_bn_prelu(mnt_conv, (256,1,1), 'mnt_s_1_1')\n",
    "    mnt_s_2=Conv2D(1, (1,1), padding='same', name='mnt_s_1_2')(mnt_s_1)\n",
    "    \n",
    "    mnt_s_out=Activation('sigmoid', name='mnt_s_out')(mnt_s_2)\n",
    "\n",
    "    if args.mode == 'deploy':\n",
    "        feature= Flatten()(mnt_conv)\n",
    "        feature = Dense(512, activation='relu', name='feature')(feature)\n",
    "        model = Model(inputs=[img_input,], outputs=[enh_img_real, ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out,feature])\n",
    "    else:\n",
    "        model = Model(inputs=[img_input,], outputs=[ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out])     \n",
    "    if weights_path:\n",
    "        print(\"alka\")\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    return model   \n",
    "\n",
    "kernal2angle = np.reshape(np.arange(1, 180, 2, dtype=float), [1,1,1,90])/90.*np.pi #2angle = angle*2\n",
    "sin2angle, cos2angle = np.sin(kernal2angle), np.cos(kernal2angle)\n",
    "def ori2angle(ori):\n",
    "    sin2angle_ori = K.sum(ori*sin2angle, -1, keepdims=True)\n",
    "    cos2angle_ori = K.sum(ori*cos2angle, -1, keepdims=True)\n",
    "    modulus_ori = K.sqrt(K.square(sin2angle_ori)+K.square(cos2angle_ori))\n",
    "    return sin2angle_ori, cos2angle_ori, modulus_ori\n",
    "\n",
    "def ori_loss(y_true, y_pred, lamb=1.):\n",
    "    # clip\n",
    "    y_pred = K.tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # get ROI\n",
    "    label_seg = K.sum(y_true, axis=-1, keepdims=True)\n",
    "    label_seg = K.tf.cast(K.tf.greater(label_seg, 0), K.tf.float32) \n",
    "    # weighted cross entropy loss\n",
    "    lamb_pos, lamb_neg = 1., 1. \n",
    "    logloss = lamb_pos*y_true*K.log(y_pred)+lamb_neg*(1-y_true)*K.log(1-y_pred)\n",
    "    logloss = logloss*label_seg # apply ROI\n",
    "    logloss = -K.sum(logloss) / (K.sum(label_seg) + K.epsilon())\n",
    "    # coherence loss, nearby ori should be as near as possible\n",
    "    mean_kernal = np.reshape(np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]], dtype=np.float32)/8, [3, 3, 1, 1])    \n",
    "    sin2angle_ori, cos2angle_ori, modulus_ori = ori2angle(y_pred)\n",
    "    sin2angle = K.conv2d(sin2angle_ori, mean_kernal, padding='same')\n",
    "    cos2angle = K.conv2d(cos2angle_ori, mean_kernal, padding='same')\n",
    "    modulus = K.conv2d(modulus_ori, mean_kernal, padding='same')\n",
    "    coherence = K.sqrt(K.square(sin2angle) + K.square(cos2angle)) / (modulus + K.epsilon())\n",
    "    coherenceloss = K.sum(label_seg) / (K.sum(coherence*label_seg) + K.epsilon()) - 1\n",
    "    loss = logloss + lamb*coherenceloss\n",
    "    return loss\n",
    "\n",
    "def ori_o_loss(y_true, y_pred):\n",
    "    # clip\n",
    "    y_pred = K.tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # get ROI\n",
    "    label_seg = K.sum(y_true, axis=-1, keepdims=True)\n",
    "    label_seg = K.tf.cast(K.tf.greater(label_seg, 0), K.tf.float32) \n",
    "    # weighted cross entropy loss\n",
    "    lamb_pos, lamb_neg= 1., 1. \n",
    "    logloss = lamb_pos*y_true*K.log(y_pred)+lamb_neg*(1-y_true)*K.log(1-y_pred)\n",
    "    logloss = logloss*label_seg # apply ROI\n",
    "    logloss = -K.sum(logloss) / (K.sum(label_seg) + K.epsilon())\n",
    "    return logloss\n",
    "\n",
    "def seg_loss(y_true, y_pred, lamb=1.):\n",
    "    # clip\n",
    "    y_pred = K.tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # weighted cross entropy loss\n",
    "    total_elements = K.sum(K.tf.ones_like(y_true))\n",
    "    label_pos = K.tf.cast(K.tf.greater(y_true, 0.0), K.tf.float32)   \n",
    "    lamb_pos = 0.5 * total_elements / K.sum(label_pos)\n",
    "    lamb_neg = 1 / (2 - 1/lamb_pos)\n",
    "    logloss = lamb_pos*y_true*K.log(y_pred)+lamb_neg*(1-y_true)*K.log(1-y_pred)\n",
    "    logloss = -K.mean(K.sum(logloss, axis=-1))\n",
    "    # smooth loss\n",
    "    smooth_kernal = np.reshape(np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]], dtype=np.float32)/8, [3, 3, 1, 1])\n",
    "    smoothloss = K.mean(K.abs(K.conv2d(y_pred, smooth_kernal)))\n",
    "    loss = logloss + lamb*smoothloss\n",
    "    return loss\n",
    "\n",
    "def mnt_s_loss(y_true, y_pred):\n",
    "    # clip\n",
    "    y_pred = K.tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # get ROI\n",
    "    label_seg = K.tf.cast(K.tf.not_equal(y_true, 0.0), K.tf.float32) \n",
    "    y_true = K.tf.where(K.tf.less(y_true,0.0), K.tf.zeros_like(y_true), y_true) # set -1 -> 0\n",
    "    # weighted cross entropy loss       \n",
    "    total_elements = K.sum(label_seg) + K.epsilon()  \n",
    "    lamb_pos, lamb_neg = 10., .5\n",
    "    logloss = lamb_pos*y_true*K.log(y_pred)+lamb_neg*(1-y_true)*K.log(1-y_pred)\n",
    "    # apply ROI\n",
    "    logloss = logloss*label_seg\n",
    "    logloss = -K.sum(logloss) / total_elements\n",
    "    return logloss    \n",
    "\n",
    "# find highest peak using gaussian\n",
    "def ori_highest_peak(y_pred, length=180):\n",
    "    glabel = gausslabel(length=length,stride=2).astype(np.float32)\n",
    "    ori_gau = K.conv2d(y_pred,glabel,padding='same')\n",
    "    return ori_gau\n",
    "\n",
    "def ori_acc_delta_k(y_true, y_pred, k=10, max_delta=180):\n",
    "    # get ROI\n",
    "    label_seg = K.sum(y_true, axis=-1)\n",
    "    label_seg = K.tf.cast(K.tf.greater(label_seg, 0), K.tf.float32) \n",
    "    # get pred angle    \n",
    "    angle = K.cast(K.argmax(ori_highest_peak(y_pred, max_delta), axis=-1), dtype=K.tf.float32)*2.0+1.0\n",
    "    # get gt angle\n",
    "    angle_t = K.cast(K.argmax(y_true, axis=-1), dtype=K.tf.float32)*2.0+1.0\n",
    "    # get delta\n",
    "    angle_delta = K.abs(angle_t - angle)\n",
    "    acc = K.tf.less_equal(K.minimum(angle_delta, max_delta-angle_delta), k)\n",
    "    acc = K.cast(acc, dtype=K.tf.float32)\n",
    "    # apply ROI\n",
    "    acc = acc*label_seg\n",
    "    acc = K.sum(acc) / (K.sum(label_seg)+K.epsilon())\n",
    "    return acc\n",
    "def ori_acc_delta_10(y_true, y_pred):\n",
    "    return ori_acc_delta_k(y_true, y_pred, 10)\n",
    "def ori_acc_delta_20(y_true, y_pred):\n",
    "    return ori_acc_delta_k(y_true, y_pred, 20)\n",
    "def mnt_acc_delta_10(y_true, y_pred):\n",
    "    return ori_acc_delta_k(y_true, y_pred, 10, 360)\n",
    "def mnt_acc_delta_20(y_true, y_pred):\n",
    "    return ori_acc_delta_k(y_true, y_pred, 20, 360)    \n",
    "\n",
    "def seg_acc_pos(y_true, y_pred):\n",
    "    y_true = K.tf.where(K.tf.less(y_true,0.0), K.tf.zeros_like(y_true), y_true)\n",
    "    acc = K.cast(K.equal(y_true, K.round(y_pred)), dtype=K.tf.float32)\n",
    "    acc = K.sum(acc * y_true) / (K.sum(y_true)+K.epsilon())\n",
    "    return acc    \n",
    "def seg_acc_neg(y_true, y_pred):\n",
    "    y_true = K.tf.where(K.tf.less(y_true,0.0), K.tf.zeros_like(y_true), y_true)\n",
    "    acc = K.cast(K.equal(y_true, K.round(y_pred)), dtype=K.tf.float32)\n",
    "    acc = K.sum(acc * (1-y_true)) / (K.sum(1-y_true)+K.epsilon())\n",
    "    return acc\n",
    "def seg_acc_all(y_true, y_pred):\n",
    "    y_true = K.tf.where(K.tf.less(y_true,0.0), K.tf.zeros_like(y_true), y_true)\n",
    "    return K.mean(K.equal(y_true, K.round(y_pred)))  \n",
    "\n",
    "def mnt_mean_delta(y_true, y_pred):\n",
    "    # get ROI\n",
    "    label_seg = K.sum(y_true, axis=-1)\n",
    "    label_seg = K.tf.cast(K.tf.greater(label_seg, 0), K.tf.float32) \n",
    "    # get pred pos    \n",
    "    pos = K.cast(K.argmax(y_pred, axis=-1), dtype=K.tf.float32)\n",
    "    # get gt pos\n",
    "    pos_t = K.cast(K.argmax(y_true, axis=-1), dtype=K.tf.float32)\n",
    "    # get delta\n",
    "    pos_delta = K.abs(pos_t - pos)\n",
    "    # apply ROI\n",
    "    pos_delta = pos_delta*label_seg\n",
    "    mean_delta = K.sum(pos_delta) / (K.sum(label_seg)+K.epsilon())\n",
    "    return mean_delta\n",
    "\n",
    "# def train(input_shape=(512,512,1)):\n",
    "#     print(\"train\")\n",
    "#     img_name, folder_name, img_size = get_maximum_img_size_and_names(train_set, train_sample_rate)  \n",
    "#     main_net_model = get_main_net((img_size[0],img_size[1],1), pretrain)\n",
    "#     plot_model(main_net_model, to_file=output_dir+'/model.png',show_shapes=True)\n",
    "#     adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)    \n",
    "#     main_net_model.compile(optimizer=adam, \n",
    "#         loss={'ori_out_1':ori_loss, 'ori_out_2':ori_o_loss, 'seg_out':seg_loss, \n",
    "#                 'mnt_o_out':ori_o_loss, 'mnt_w_out':ori_o_loss, 'mnt_h_out':ori_o_loss, 'mnt_s_out':mnt_s_loss}, \n",
    "#         loss_weights={'ori_out_1':.1, 'ori_out_2':.1, 'seg_out':10., \n",
    "#                 'mnt_w_out':.5, 'mnt_h_out':.5, 'mnt_o_out':.5,'mnt_s_out':200.},\n",
    "#         metrics={'ori_out_1':[ori_acc_delta_10,],\n",
    "#                  'ori_out_2':[ori_acc_delta_10,],\n",
    "#                  'seg_out':[seg_acc_pos, seg_acc_neg, seg_acc_all],\n",
    "#                  'mnt_o_out':[mnt_acc_delta_10,],\n",
    "#                  'mnt_w_out':[mnt_mean_delta,],\n",
    "#                  'mnt_h_out':[mnt_mean_delta,],\n",
    "#                  'mnt_s_out':[seg_acc_pos, seg_acc_neg, seg_acc_all]})\n",
    "#     for epoch in range(1):\n",
    "#         for i, train in enumerate(load_data((img_name, folder_name, img_size), tra_ori_model, rand=True, aug=0.7, batch_size=batch_size)):\n",
    "#             loss = main_net_model.train_on_batch(train[0], \n",
    "#                 {'ori_out_1':train[1], 'ori_out_2':train[2], 'seg_out':train[3],\n",
    "#                 'mnt_w_out':train[4], 'mnt_h_out':train[5], 'mnt_o_out':train[6], 'mnt_s_out':train[7]})  \n",
    "#             if i%(20/batch_size) == 0:\n",
    "#                 logging.info(\"epoch=%d, step=%d\", epoch, i)\n",
    "#                 logging.info(\"%s\", \" \".join([\"%s:%.4f\\n\"%(x) for x in zip(main_net_model.metrics_names, loss)]))\n",
    "#             if i%(10000/batch_size) == (10000/batch_size)-1:\n",
    "#                 # test every 10000 pics\n",
    "#                 outdir = \"%s/%03d_%05d/\"%(output_dir, epoch, i)\n",
    "#                 re_mkdir(outdir)\n",
    "#                 savedir = \"%s%s\"%(outdir, str(epoch)+'_'+str(i))\n",
    "#                 main_net_model.save_weights(savedir, True)\n",
    "#                 for folder in test_set:\n",
    "#                     test([folder,], savedir, outdir, test_num=10, draw=False)\n",
    "#     return\n",
    "\n",
    "# currently can only produce one each time\n",
    "def label2mnt(mnt_s_out, mnt_w_out, mnt_h_out, mnt_o_out, thresh=0.5):\n",
    "    mnt_s_out = np.squeeze(mnt_s_out)\n",
    "    mnt_w_out = np.squeeze(mnt_w_out)\n",
    "    mnt_h_out = np.squeeze(mnt_h_out)\n",
    "    mnt_o_out = np.squeeze(mnt_o_out)\n",
    "    assert len(mnt_s_out.shape)==2 and len(mnt_w_out.shape)==3 and len(mnt_h_out.shape)==3 and len(mnt_o_out.shape)==3 \n",
    "    # get cls results\n",
    "    mnt_sparse = sparse.coo_matrix(mnt_s_out>thresh)\n",
    "    print(mnt_sparse.row.shape)\n",
    "    print(mnt_sparse.col.shape)\n",
    "    mnt_list = np.array(list(zip(mnt_sparse.row, mnt_sparse.col)), dtype=np.int32)\n",
    "    if mnt_list.shape[0] == 0:\n",
    "        return np.zeros((0, 4))\n",
    "    # get regression results\n",
    "    mnt_w_out = np.argmax(mnt_w_out, axis=-1)\n",
    "    mnt_h_out = np.argmax(mnt_h_out, axis=-1)\n",
    "    mnt_o_out = np.argmax(mnt_o_out, axis=-1) # TODO: use ori_highest_peak(np version)\n",
    "    # get final mnt\n",
    "    mnt_final = np.zeros((len(mnt_list), 4))\n",
    "    mnt_final[:, 0] = mnt_sparse.col*8 + mnt_w_out[mnt_list[:,0], mnt_list[:,1]]\n",
    "    mnt_final[:, 1] = mnt_sparse.row*8 + mnt_h_out[mnt_list[:,0], mnt_list[:,1]]\n",
    "    mnt_final[:, 2] = (mnt_o_out[mnt_list[:,0], mnt_list[:,1]]*2-89.)/180*np.pi\n",
    "    mnt_final[mnt_final[:, 2]<0.0, 2] = mnt_final[mnt_final[:, 2]<0.0, 2]+2*np.pi\n",
    "    mnt_final[:, 3] = mnt_s_out[mnt_list[:,0], mnt_list[:, 1]]\n",
    "    return mnt_final\n",
    "# def test(test_set, model, outdir, test_num=10, draw=True):\n",
    "#     img_name, folder_name, img_size = get_maximum_img_size_and_names(test_set)\n",
    "#     logging.info(\"Testing %s:\"%(test_set))\n",
    "#     print(img_size)\n",
    "   \n",
    "#     # image = cv2.resize(img_size, (512, 512))\n",
    "#     # print(image.shape)\n",
    "#     # image = np.expand_dims(img_size, axis=-1)  \n",
    "#     # print(image.shape)\n",
    "#     # image = np.expand_dims(img_size, axis=0)  \n",
    "#     # print(image.shape)\n",
    "  \n",
    "#     main_net_model = get_main_net((img_size[0],img_size[1],1), model)\n",
    "#     nonsense = SGD(lr=0.0, momentum=0.0, decay=0.0, nesterov=False)    \n",
    "#     main_net_model.compile(optimizer=nonsense,\n",
    "#         loss={'ori_out_1':ori_loss, 'ori_out_2':ori_o_loss, 'seg_out':seg_loss, \n",
    "#                 'mnt_o_out':ori_o_loss, 'mnt_w_out':ori_o_loss, 'mnt_h_out':ori_o_loss, 'mnt_s_out':mnt_s_loss}, \n",
    "#         loss_weights={'ori_out_1':.1, 'ori_out_2':.1, 'seg_out':10., \n",
    "#                 'mnt_w_out':.5, 'mnt_h_out':.5, 'mnt_o_out':.5,'mnt_s_out':200.},        \n",
    "#         metrics={'ori_out_1':[ori_acc_delta_10,ori_acc_delta_20],\n",
    "#                  'ori_out_2':[ori_acc_delta_10,ori_acc_delta_20],\n",
    "#                  'seg_out':[seg_acc_pos, seg_acc_neg, seg_acc_all],\n",
    "#                  'mnt_o_out':[mnt_acc_delta_10,mnt_acc_delta_20],\n",
    "#                  'mnt_w_out':[mnt_mean_delta,],\n",
    "#                  'mnt_h_out':[mnt_mean_delta,],\n",
    "#                  'mnt_s_out':[seg_acc_pos, seg_acc_neg, seg_acc_all]})\n",
    "#     ave_loss, ave_prf_nms = [], []\n",
    "#     for j, test in enumerate(load_data((img_name, folder_name, img_size), tra_ori_model, rand=False, aug=0.0, batch_size=1)):      \n",
    "#         if j < test_num:\n",
    "#             logging.info(\"%d / %d: %s\"%(j+1, len(img_name), img_name[j]))   \n",
    "#             print(\"test\",test[0].shape) \n",
    "#             ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out,feature  = main_net_model.predict(test[0])\n",
    "#             metrics = main_net_model.train_on_batch(test[0], \n",
    "#                 {'ori_out_1':test[1], 'ori_out_2':test[2], 'seg_out':test[3],\n",
    "#                 'mnt_w_out':test[4], 'mnt_h_out':test[5], 'mnt_o_out':test[6], 'mnt_s_out':test[7]})  \n",
    "#             ave_loss.append(metrics)\n",
    "#             logging.info(\"%s\", \" \".join([\"%s:%.4f\\n\"%(x) for x in zip(main_net_model.metrics_names, metrics)]))\n",
    "#             mnt_gt = label2mnt(test[7], test[4], test[5], test[6])\n",
    "#             mnt_s_out = mnt_s_out * test[3]\n",
    "#             mnt = label2mnt(mnt_s_out, mnt_w_out, mnt_h_out, mnt_o_out, thresh=0.5)\n",
    "#             mnt_nms = nms(mnt)\n",
    "#             p, r, f, l, o = mnt_P_R_F(mnt_gt, mnt_nms)\n",
    "#             logging.info(\"After_nms:\\nprecision: %f\\nrecall: %f\\nf1-measure: %f\\nlocation_dis: %f\\norientation_delta:%f\\n----------------\\n\"%(\n",
    "#                 p, r, f, l, o))\n",
    "#             ave_prf_nms.append([p, r, f, l, o])            \n",
    "#             if draw:                         \n",
    "#                 angval = run(ori_highest_peak(ori_out_1))                           \n",
    "#                 angval = (np.argmax(angval, axis=-1)*2-90)/180.*np.pi\n",
    "#                 draw_ori_on_imgs(test[0], angval, seg_out, \"%s%s_ori.png\"%(outdir, test[8][0]))\n",
    "#                 draw_minutiaes(test[0], mnt_nms[:,:3], \"%s%s_mnt.png\"%(outdir, test[8][0]))\n",
    "#                 draw_minutiaes(test[0], mnt_gt[:,:3], \"%s%s_mnt_gt.png\"%(outdir, test[8][0]))\n",
    "#         else:\n",
    "#             break\n",
    "#     logging.info(\"Average testing results:\")\n",
    "#     ave_loss = np.mean(np.array(ave_loss), 0)\n",
    "#     ave_prf_nms = np.mean(np.array(ave_prf_nms), 0)\n",
    "#     logging.info(\"\\n%s\\n\", \" \".join([\"%s:%.4f\\n\"%(x) for x in zip(main_net_model.metrics_names, ave_loss)]))\n",
    "#     logging.info(\"After_nms:\\nprecision: %f\\nrecall: %f\\nf1-measure: %f\\nlocation_dis: %f\\norientation_delta:%f\\n----------------\\n\"%(\n",
    "#                     ave_prf_nms[0],ave_prf_nms[1],ave_prf_nms[2],ave_prf_nms[3],ave_prf_nms[4]))     \n",
    "#     return\n",
    "# #new addition\n",
    "\n",
    "def draw_minutiaes(image, minutiae, fname, r=15):\n",
    "    image = np.squeeze(image)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "\n",
    "    plt.plot(minutiae[:, 0], minutiae[:, 1], 'rs', fillstyle='none', linewidth=1)\n",
    "    for x, y, o in minutiae:\n",
    "        plt.plot([x, x + r * np.cos(o)], [y, y + r * np.sin(o)], 'r-')\n",
    "    plt.axis([0, image.shape[1], image.shape[0], 0])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=0)\n",
    "    # plt.savefig('output1.png', bbox_inches='tight', pad_inches=0)\n",
    "    # plt.show()  # Display the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "def draw_ori_on_imgs(img, ori, mask, fname, coh=None, stride=16):\n",
    "    # print(\"nafees\")\n",
    "    ori = np.squeeze(ori)\n",
    "    mask = np.squeeze(np.round(mask))\n",
    "    img = np.squeeze(img)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    ori = ndimage.zoom(ori, np.array(img.shape) / np.array(ori.shape, dtype=float), order=0)\n",
    "    if mask.shape != img.shape:\n",
    "        mask = ndimage.zoom(mask, np.array(img.shape) / np.array(mask.shape, dtype=float), order=0)\n",
    "    if coh is None:\n",
    "        coh = np.ones_like(img)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for i in range(stride, img.shape[0], stride):\n",
    "        for j in range(stride, img.shape[1], stride):\n",
    "            if mask[i, j] == 0:\n",
    "                continue\n",
    "            x, y, o, r = j, i, ori[i, j], coh[i, j] * (stride * 0.9)\n",
    "            plt.plot([x, x + r * np.cos(o)], [y, y + r * np.sin(o)], 'r-')\n",
    "    plt.axis([0, img.shape[1], img.shape[0], 0])\n",
    "    plt.axis('off')\n",
    "    plt.savefig(fname, bbox_inches='tight', pad_inches=0)\n",
    "    # plt.savefig('output2.png', bbox_inches='tight', pad_inches=0)\n",
    "    # plt.show()  # Display the plot\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def deploy(deploy_set, set_name=None):\n",
    "    features_dict={}\n",
    "    if set_name is None:\n",
    "        set_name = deploy_set.split('/')[-2]\n",
    "    mkdir(output_dir+'/'+set_name+'/')\n",
    "    logging.info(\"Predicting %s:\"%(set_name)) \n",
    "    _, img_name = get_files_in_folder(deploy_set, '.tiff')\n",
    "    if len(img_name) == 0:\n",
    "        deploy_set = deploy_set+'images/'\n",
    "        _, img_name = get_files_in_folder(deploy_set, '.tiff')\n",
    "    img_size = cv2.imread(deploy_set+img_name[0]+'.tiff').shape\n",
    "    img_size = np.array(img_size, dtype=np.int32)/8*8      \n",
    "    main_net_model = get_main_net((img_size[0],img_size[1],1), pretrain)\n",
    "    _, img_name = get_files_in_folder(deploy_set, '.tiff')\n",
    "    time_c = []\n",
    "    for i in range(0,len(img_name)):\n",
    "        logging.info(\"%s %d / %d: %s\"%(set_name, i+1, len(img_name), img_name[i]))\n",
    "        time_start = time()  \n",
    "        #read image in grayscale\n",
    "        #  \n",
    "        # image = cv2.imread(deploy_set+img_name[i]+'.tif',0) / 255.0\n",
    "        \n",
    "        # # Extract the label from the image name without considering variations\n",
    "        # image_name_ex = image.split('.')[0]\n",
    "\n",
    "        \n",
    "        # Assuming `deploy_set`, `img_name`, and `i` are defined properly\n",
    "        image = cv2.imread(deploy_set + img_name[i] + '.tiff', 0) / 255.0\n",
    "\n",
    "        # Extract the label from the image name without considering variations\n",
    "        img_filename = img_name[i] + '.tiff'\n",
    "        image_name_ex = img_filename.split('.')[0]\n",
    "            \n",
    "        image = image[:int(img_size[0]), :int(img_size[1])] \n",
    "        # print(image.shape) \n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        # print(image.shape)\n",
    "        image = np.expand_dims(image, axis=-1)  \n",
    "        # print(image.shape)\n",
    "        image = np.expand_dims(image, axis=0)  \n",
    "        # print(image.shape)\n",
    "       \n",
    "        # image = np.reshape(image,[1, image.shape[0], image.shape[1], 1])\n",
    "        enhance_img, ori_out_1, ori_out_2, seg_out, mnt_o_out, mnt_w_out, mnt_h_out, mnt_s_out,feature = main_net_model.predict(image) \n",
    "        # Store the image name and features in a dictionary\n",
    "        \n",
    "        # print(\"Feature:\",feature)\n",
    "        # print(\"Image Name:\", image_name_ex)\n",
    "        features_dict[image_name_ex] = feature  \n",
    "\n",
    "        time_afterconv = time()\n",
    "        round_seg = np.round(np.squeeze(seg_out))\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(5, 5))\n",
    "        seg_out = cv2.morphologyEx(round_seg, cv2.MORPH_OPEN, kernel)\n",
    "        mnt = label2mnt(np.squeeze(mnt_s_out)*np.round(np.squeeze(seg_out)), mnt_w_out, mnt_h_out, mnt_o_out, thresh=0.5)\n",
    "        mnt_nms = nms(mnt)\n",
    "        ori = (ori_highest_peak(ori_out_1))                           \n",
    "        ori = (np.argmax(ori, axis=-1)*2-90)/180.*np.pi  \n",
    "        time_afterpost = time()\n",
    "        mnt_writer(mnt_nms, img_name[i], img_size, \"%s/%s/%s.mnt\"%(output_dir, set_name, img_name[i]))        \n",
    "        # draw_ori_on_imgs(image, ori, np.ones_like(seg_out), \"%s/%s/%s_ori.png\"%(output_dir, set_name, img_name[i]))        \n",
    "        # draw_minutiaes(image, mnt_nms[:,:3], \"%s/%s/%s_mnt.png\"%(output_dir, set_name, img_name[i]))\n",
    "        \n",
    "        # cv2.imwrite(\"%s/%s/%s_enh.png\"%(output_dir, set_name, img_name[i]), np.squeeze(enhance_img)*ndimage.zoom(np.round(np.squeeze(seg_out)), [8,8], order=0))\n",
    "        # cv2.imwrite(\"%s/%s/%s_seg.png\"%(output_dir, set_name, img_name[i]), ndimage.zoom(np.round(np.squeeze(seg_out)), [8,8], order=0)) \n",
    "        # io.savemat(\"%s/%s/%s.mat\"%(output_dir, set_name, img_name[i]), {'orientation':ori, 'orientation_distribution_map':ori_out_1})\n",
    "        time_afterdraw = time()\n",
    "        time_c.append([time_afterconv-time_start, time_afterpost-time_afterconv, time_afterdraw-time_afterpost])\n",
    "        logging.info(\"load+conv: %.3fs, seg-postpro+nms: %.3f, draw: %.3f\"%(time_c[-1][0],time_c[-1][1],time_c[-1][2]))\n",
    "    \n",
    "    # serialized_dict = \"\\n\".join([f\"{key}: {value}\" for key, value in features_dict.items()])\n",
    "    # import pickle\n",
    " \n",
    "\n",
    "    # with open(\"features_dict_fvc2006_db2a.pkl\", \"wb\") as file:\n",
    "        # pickle.dump(features_dict, file)\n",
    "    time_c = np.mean(np.array(time_c),axis=0)\n",
    "    logging.info(\"Average: load+conv: %.3fs, oir-select+seg-post+nms: %.3f, draw: %.3f\"%(time_c[0],time_c[1],time_c[2]))\n",
    "    return  \n",
    "\n",
    "def main():\n",
    "    if args.mode == 'train':\n",
    "        train()\n",
    "    elif args.mode == 'test':        \n",
    "        for folder in test_set:\n",
    "            test([folder,], pretrain, output_dir+\"/\", test_num=258, draw=False) \n",
    "    elif args.mode == 'deploy':\n",
    "        for i, folder in enumerate(deploy_set):\n",
    "            deploy(folder, str(i))\n",
    "    else:\n",
    "        pass\n",
    "#%%\n",
    "if __name__ =='__main__':\n",
    "    # args\n",
    "    main()\n",
    "    # train()\n",
    "    # for folder in test_set:\n",
    "    #     test([folder,], pretrain, output_dir+\"/\", test_num=258, draw=False) \n",
    "    # for folder in deploy_set:\n",
    "    #     deploy(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Load the dictionary from the pickle file\n",
    "# with open(\"features_dict_fvc2006_db2a.pkl\", \"rb\") as file:\n",
    "#     features_dict = pickle.load(file)\n",
    "#     print(features_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "few_shot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
